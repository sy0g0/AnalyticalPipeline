{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込みと前処理を行うためのnotebookです。  \n",
    "モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\momoka.miyaguchi.kd\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\momoka.miyaguchi.kd\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\momoka.miyaguchi.kd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "%pip install scikit-learn\n",
    "%pip install imblearn\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df):\n",
    "    \"\"\"\n",
    "    指定された列を二値化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        二値化対象のデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        二値化されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    指定されたファイルからデータを読み込み、前処理を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        読み込むデータファイルのパス。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        前処理されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('../data/raw/train.csv')\n",
    "test = read_data('../data/raw/test.csv')\n",
    "\n",
    "new_transactions = pd.read_csv('../data/raw/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_month_diff(transactions):\n",
    "    \"\"\"\n",
    "    purchase_dateとmonth_lagを基にmonth_diffを計算する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        month_diff列が追加されたデータフレーム。\n",
    "    \"\"\"\n",
    "    current_date = pd.Timestamp(datetime.datetime.today())\n",
    "    transactions['month_diff'] = ((current_date - transactions['purchase_date']).dt.days) // 30\n",
    "    transactions['month_diff'] += transactions['month_lag']\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df, columns):\n",
    "    \"\"\"\n",
    "    指定されたカテゴリカル列をワンホットエンコーディングする。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        エンコード対象のデータフレーム。\n",
    "    columns : list of str\n",
    "        エンコードするカテゴリカル列のリスト。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ワンホットエンコードされたデータフレーム。\n",
    "    \"\"\"\n",
    "    # ダミー変数\n",
    "    return pd.get_dummies(df, columns=columns)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_transactions(history):\n",
    "    \"\"\"\n",
    "    取引データを集計する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).astype(np.int64) * 1e-9\n",
    "\n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_A': ['mean'],\n",
    "        'category_3_B': ['mean'],\n",
    "        'category_3_C': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['mean', 'max', 'min', 'std'],\n",
    "        'month_diff': ['mean']\n",
    "    }\n",
    "\n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "\n",
    "    df = (history.groupby('card_id').size().reset_index(name='transactions_count'))\n",
    "\n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "\n",
    "    return agg_history\n",
    "\n",
    "\n",
    "def aggregate_per_month(history):\n",
    "    \"\"\"\n",
    "    月ごとの取引データを集計する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        月ごとに集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "        'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "        'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "    }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "\n",
    "    return final_group\n",
    "\n",
    "\n",
    "def successive_aggregates(df, field1, field2):\n",
    "    \"\"\"\n",
    "    指定されたフィールドを基に連続集計を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    field1 : str\n",
    "        集計の基準となるフィールド。\n",
    "    field2 : str\n",
    "        集計されるフィールド。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        連続集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    t = df.groupby(['card_id', field1])[field2].mean()\n",
    "    u = pd.DataFrame(t).reset_index().groupby('card_id')[field2].agg(['mean', 'min', 'max', 'std'])\n",
    "    u.columns = [field1 + '_' + field2 + '_' + col for col in u.columns.values]\n",
    "    u.reset_index(inplace=True)\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1332.66 Mb (57.1% reduction)\n",
      "Mem. usage decreased to 86.12 Mb (58.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "# 日付型に変換\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "\n",
    "# 月の差を計算\n",
    "historical_transactions = calculate_month_diff(historical_transactions)\n",
    "new_transactions = calculate_month_diff(new_transactions)\n",
    "\n",
    "# カテゴリカル列をワンホットエンコーディング\n",
    "historical_transactions = encode_categorical_columns(historical_transactions, ['category_2', 'category_3'])\n",
    "new_transactions = encode_categorical_columns(new_transactions, ['category_2', 'category_3'])\n",
    "\n",
    "# メモリ使用量の削減\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "# authorized_flagの平均を計算\n",
    "agg_fun = {'authorized_flag': ['mean']}\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "\n",
    "# purchase_month列を追加\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "\n",
    "# データの集計\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "\n",
    "# 月ごとのデータの集計\n",
    "final_group = aggregate_per_month(authorized_transactions)\n",
    "\n",
    "# 連続集計\n",
    "additional_fields = successive_aggregates(new_transactions, 'category_1', 'purchase_amount')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'installments', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'city_id', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'category_1', 'installments'), on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, additional_fields, on='card_id', how='left')\n",
    "test = pd.merge(test, additional_fields, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 164)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再読み込み\n",
    "new_transactions = pd.read_csv('../data/raw/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv', parse_dates=['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_month_diff(df):\n",
    "    \"\"\"\n",
    "    DataFrame `df` に対して月差分を計算し、新しい列として追加した後、\n",
    "    card_idごとに月差分の統計量（平均、最小値、最大値）を計算して返す関数。\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): 月差分を計算する対象のデータフレーム。'purchase_date' 列がdatetime型であることが前提。\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: card_idごとに計算された月差分の統計量（'card_id', 'month_elapsed_mean', 'month_elapsed_min', 'month_elapsed_max' を含む）を持つデータフレーム。\n",
    "    \"\"\"\n",
    "    # 現在の日付を取得し、タイムスタンプに変換\n",
    "    current_date = pd.Timestamp(datetime.datetime.today())\n",
    "\n",
    "    # purchase_date 列をdatetime型に変換\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "\n",
    "    # 月差分を計算し、新しい列として追加\n",
    "    df['month_elapsed'] = df['purchase_date'].apply(lambda x: relativedelta(current_date, x).months)\n",
    "\n",
    "    # 月の異常な取引を算出\n",
    "    df['month_elapsed'] += df['month_lag']\n",
    "\n",
    "    # card_idごとにmonth_elapsedの計算\n",
    "    month_diff_mean = df.groupby('card_id')['month_elapsed'].agg(['mean', 'min', 'max']).astype('float32').reset_index()\n",
    "\n",
    "    # 列名をリネームして返す\n",
    "    month_diff_result = month_diff_mean.rename(columns={\n",
    "        'mean': 'month_elapsed_mean',\n",
    "        'min': 'month_elapsed_min',\n",
    "        'max': 'month_elapsed_max'\n",
    "        # 'std': 'month_elapsed_std'\n",
    "    })\n",
    "\n",
    "    return month_diff_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactionsに関しては'authorized_flag'がNのデータを使用して算出する\n",
    "fill0_history = historical_transactions[historical_transactions['authorized_flag'] == \"N\"].copy()\n",
    "\n",
    "history_month_diff = calculate_month_diff(fill0_history)\n",
    "# new_month_diff = calculate_month_diff(new_transactions)\n",
    "\n",
    "# カラム名を変更\n",
    "# 正しいカラム名のリストに修正する\n",
    "history_month_diff.columns = ['card_id', 'history_month_elapsed_mean', 'history_month_elapsed_min', 'history_month_elapsed_max']\n",
    "# new_month_diff.columns = ['card_id', 'new_month_elapsed_mean', 'new_month_elapsed_min', 'new_month_elapsed_max']\n",
    "# new_month_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合\n",
    "train = pd.merge(train, history_month_diff, on='card_id', how='left')\n",
    "test = pd.merge(test, history_month_diff, on='card_id', how='left')\n",
    "\n",
    "# train = pd.merge(train, new_month_diff, on='card_id', how='left')\n",
    "# test = pd.merge(test, new_month_diff, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加の特徴量[2]\n",
    "# 最後に購入した日の購入額\n",
    "# 最後に購入した日\n",
    "\n",
    "def last_purcase_amount(df):\n",
    "    last_purchase_date = df.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "\n",
    "    # 最終購入日の金額を取得する\n",
    "    merge_last_purchase = pd.merge(last_purchase_date, df[['card_id', 'purchase_date', 'purchase_amount']], on=['card_id', 'purchase_date'], how='inner')\n",
    "    umerge_last_purchase = merge_last_purchase.groupby('card_id').agg({'purchase_amount': 'mean'}).reset_index()\n",
    "    return umerge_last_purchase\n",
    "# re_last_purchase.drop(columns=['purcahse_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_amount = last_purcase_amount(historical_transactions)\n",
    "# new_amount = last_purcase_amount(new_transactions)\n",
    "\n",
    "# 不要な行を削除\n",
    "# history_amount = history_amount.drop(columns=['purchase_date'])\n",
    "# new_amount = new_amount.drop(columns=['purchase_date'])\n",
    "\n",
    "# カラム名の変更\n",
    "history_amount.columns = ['card_id', 'history_last_amount']\n",
    "# new_amount.columns = ['card_id', 'new_last_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合\n",
    "train = pd.merge(train, history_amount, on='card_id', how='left')\n",
    "test = pd.merge(test, history_amount, on='card_id', how='left')\n",
    "\n",
    "# train = pd.merge(train, new_amount, on='card_id', how='left')\n",
    "# test = pd.merge(test, new_amount, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card_idの重複確認\n",
    "# duplicate_cards = re_last_purchase[train.duplicated('card_id')]\n",
    "# print(\"Duplicate card_ids:\\n\", duplicate_cards['card_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加の特徴量[3]\n",
    "# 一番取引額が多い金額\n",
    "def max_amount(df):\n",
    "    most_amount = df.groupby('card_id')['purchase_amount'].agg({'max', 'min'}).astype('float32').reset_index()\n",
    "    most_amount.rename(columns={'max': 'max_purchase_amount', 'min': 'min_purchase_amount'}, inplace=True)\n",
    "    return most_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_amount = max_amount(historical_transactions)\n",
    "# new_max_amount = max_amount(new_transactions)\n",
    "\n",
    "history_amount.columns = ['card_id', 'history_max_purchase_amount', 'history_min_purchase_amount']\n",
    "# new_max_amount.columns = ['card_id', 'new_max_purchase_amount', 'new_max_purchase_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, history_amount, on='card_id', how='left')\n",
    "test = pd.merge(test, history_amount, on='card_id', how='left')\n",
    "\n",
    "# train = pd.merge(train, new_max_amount, on='card_id', how='left')\n",
    "# test = pd.merge(test, new_max_amount, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最高購入金額 - 最小購入金額\n",
    "\n",
    "def purchase_amount_diff(df):\n",
    "    amount_diff = df.groupby('card_id')['purchase_amount'].agg({'max', 'min'}).reset_index()\n",
    "    amount_diff['max_min_amount_dff'] = amount_diff['max'] - amount_diff['min']\n",
    "    diff_amount = amount_diff[['card_id', 'max_min_amount_dff']]\n",
    "    return diff_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_amount_diff = purchase_amount_diff(historical_transactions)\n",
    "# new_amount_diff = purchase_amount_diff(new_transactions)\n",
    "\n",
    "history_amount_diff.columns = ['card_id', 'history_max_min_amount']\n",
    "# new_amount_diff.columns = ['card_id', 'new_max_min_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, history_amount_diff, on='card_id', how='left')\n",
    "test = pd.merge(test, history_amount_diff, on='card_id', how='left')\n",
    "\n",
    "# train = pd.merge(train, new_amount_diff, on='card_id', how='left')\n",
    "# test = pd.merge(test, new_amount_diff, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加の特徴量[5]\n",
    "# purchase_date を日付型に変換\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "\n",
    "# 今日の日付を取得\n",
    "current_date = pd.Timestamp(datetime.datetime.today())\n",
    "\n",
    "# first_last_dates を作成\n",
    "first_last_dates = historical_transactions.groupby('card_id').agg({\n",
    "    'purchase_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# 取引期間を計算\n",
    "first_last_dates.columns = ['card_id', 'first_purchase_date', 'last_purchase_date']\n",
    "first_last_dates['transaction_days'] = (first_last_dates['last_purchase_date'] - first_last_dates['first_purchase_date']).dt.days\n",
    "\n",
    "# month_lag はそのまま使う\n",
    "df_his = historical_transactions[['card_id', 'purchase_date', 'month_lag']]\n",
    "\n",
    "# 不要な列を削除\n",
    "del historical_transactions\n",
    "\n",
    "# 月差分（month_diff）を計算し、新しい列として追加\n",
    "df_his['month_diff'] = (((current_date - df_his['purchase_date']).dt.days) // 30).astype('int16')\n",
    "# 月の異常な取引を算出\n",
    "df_his['month_diff'] += df_his['month_lag']\n",
    "\n",
    "# 不要な列を削除\n",
    "df_his.drop(columns=['purchase_date', 'month_lag'], inplace=True)\n",
    "\n",
    "# card_id ごとに month_diff の平均値を計算\n",
    "df_his_mean = df_his.groupby('card_id').agg({'month_diff': 'mean'}).astype('float32').reset_index()\n",
    "\n",
    "# killer_feature を作成\n",
    "killer_feature = pd.merge(df_his_mean, first_last_dates, on='card_id', how='inner')\n",
    "killer_feature['kil_feature'] = killer_feature['month_diff'] / killer_feature['transaction_days']\n",
    "killer_feature['kil_feature'] = killer_feature['kil_feature'].astype('float32')\n",
    "\n",
    "# 不要な列を削除\n",
    "killer_feature.drop(columns=['first_purchase_date', 'month_diff', 'last_purchase_date', 'transaction_days'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加した特徴量のデータを結合\n",
    "train = pd.merge(train, killer_feature, on='card_id', how='left')\n",
    "test = pd.merge(test, killer_feature, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # card_idの重複確認\n",
    "# duplicate_cards = train[train.duplicated('card_id')]\n",
    "# print(\"Duplicate card_ids:\\n\", duplicate_cards['card_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "# historical_transactions = reduce_mem_usage(historical_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_weekday_flags(data):\n",
    "#     # 曜日を数字に変換\n",
    "#     data['purchase_date'] = pd.to_datetime(data['purchase_date'])\n",
    "#     data['purchase_dayofweek'] = data['purchase_date'].dt.dayofweek.astype('int32')\n",
    "#     # 曜日フラグを立てる\n",
    "#     # 月曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_monday=(data['purchase_dayofweek'] == 0).astype('int32')))\n",
    "#     # # 火曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_tuesday=(data['purchase_dayofweek'] == 1).astype('int32')))\n",
    "#     # # 水曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_wednesday=(data['purchase_dayofweek'] == 2).astype('int32')))\n",
    "#     # # 木曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_thursday=(data['purchase_dayofweek'] == 3).astype('int32')))\n",
    "#     # # 金曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_friday=(data['purchase_dayofweek'] == 4).astype('int32')))\n",
    "#     # 土曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_saturday=(data['purchase_dayofweek'] == 5).astype('int32')))\n",
    "#     # 日曜日フラグ\n",
    "#     data = (data\n",
    "#         .assign(flag_sunday=(data['purchase_dayofweek'] == 6).astype('int32')))\n",
    "#     return data\n",
    "\n",
    "# df = historical_transactions[['card_id', 'purchase_date']]\n",
    "\n",
    "# # 関数を適用して曜日フラグを追加\n",
    "# week = add_weekday_flags(df)\n",
    "# df_week_flag = week[['card_id','flag_monday', 'flag_tuesday', 'flag_wednesday', 'flag_thursday', 'flag_friday', 'flag_saturday', 'flag_sunday']]\n",
    "# df_week_flag.head()\n",
    "# mode_week = week.groupby('card_id')['purchase_dayofweek'].agg(lambda x: x.mode().iloc[0]).reset_index()\n",
    "# week = pd.merge(week, mode_week, on='card_id', how='left')\n",
    "\n",
    "# 結果確認\n",
    "# week[['card_id', 'purchase_date', 'flag_monday', 'flag_tuesday', 'flag_wednesday', 'flag_thursday', 'flag_friday', 'flag_saturday', 'flag_sunday']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_week_flag = df_week_flag.groupby('card_id').agg(\n",
    "#     sum_flag_monday=('flag_monday', 'sum'),\n",
    "#     sum_flag_tuesday=('flag_tuesday', 'sum'),\n",
    "#     sum_flag_wednesday=('flag_wednesday', 'sum'),\n",
    "#     sum_flag_thursday=('flag_thursday', 'sum'),\n",
    "#     sum_flag_friday=('flag_friday', 'sum'),\n",
    "#     sum_flag_saturday=('flag_saturday', 'sum'),\n",
    "#     sum_flag_sunday=('flag_sunday', 'sum')\n",
    "# ).reset_index()\n",
    "# df_week_flag.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.merge(train, df_week_flag, on='card_id', how='left')\n",
    "# test = pd.merge(test, df_week_flag, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 172)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理終了後のデータの保存\n",
    "- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n",
    "- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240626_2_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240626_2_test.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
