{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02で前処理をしたデータの読み込みとモデルの学習を行うためのnotebookです。  \n",
    "ここで作成したモデルは **src/models/** フォルダに格納して推論の際に使うようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "%pip install scikit-learn\n",
    "%pip install imblearn\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('../data/processed/processed20240626_2_train.csv')\n",
    "test = pd.read_csv('../data/processed/processed20240626_2_test.csv')\n",
    "# 目的変数と説明変数の作成\n",
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbmのパラメータ\n",
    "param = {'num_leaves': 111,\n",
    "         'min_data_in_leaf': 149,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7522,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7083 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2634,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の情報\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = ['feature_2', 'feature_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# データをKFoldで5分割して学習\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(params=param,\n",
    "                    train_set=trn_data,\n",
    "                    num_boost_round=num_round,\n",
    "                    valid_sets=[val_data],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(100)])\n",
    "\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # ディレクトリが存在しない場合に作成する\n",
    "    directory = 'C:/Users/momoka.miyaguchi.kd/OneDrive - AMBL株式会社/Python研修/kaggle/AnalyticalPipeline/src/models/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # モデルを保存するファイルパス\n",
    "    model_file = f'{directory}/model_fold_{fold_}.pkl'\n",
    "\n",
    "    # モデルを保存\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Directory exists: {os.path.exists(directory)}\")\n",
    "print(f\"Files in directory: {os.listdir(directory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量重要度の可視化\n",
    "\n",
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,50))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('lgbm_importances.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "df_rank['rank'] = df_rank.index + 1\n",
    "df_rank.to_csv('importance_rank.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# 仮のデータフレームを作成する (重要度としてランダムな値を使用)\n",
    "np.random.seed(42)\n",
    "features = ['feature_{}'.format(i) for i in range(1, 11)]\n",
    "importance_values = np.random.rand(10)\n",
    "feature_importance_df = pd.DataFrame({'feature': features, 'importance': importance_values})\n",
    "\n",
    "# 重要度でソートして順位を付ける\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "feature_importance_df['rank'] = range(1, len(feature_importance_df) + 1)\n",
    "\n",
    "# プロットの準備\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='viridis')\n",
    "\n",
    "# 各棒の横に順位を表示する\n",
    "for index, row in feature_importance_df.iterrows():\n",
    "    plt.text(row['importance'] + 0.005, index, f'{row[\"rank\"]}', va='center')\n",
    "\n",
    "plt.title('Feature Importance Ranking')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
