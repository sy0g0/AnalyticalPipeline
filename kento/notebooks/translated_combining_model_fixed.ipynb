{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a76c616",
   "metadata": {
    "_uuid": "9e97164a7191d9d43ba8158c0f7e13aa455a0ce9"
   },
   "source": [
    "# モデルを外れ値のないモデルと組み合わせる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c1deb2",
   "metadata": {
    "_uuid": "e0f082732acbf893c2cd4c07200904effcfde928"
   },
   "source": [
    "\n",
    "前提として、特徴量エンジニアリングが完了しており、以下の2つのデータセットがあるとします。\n",
    "\n",
    "- ***train_clean.csv***: トレーニングデータセット\n",
    "- ***test_clean.csv***: テストデータセット\n",
    "\n",
    "`train_clean.csv`には1/0の値を持つ**`outlier`**カラムがあります。\n",
    "\n",
    "さらに、最良のLB提出物があります：\n",
    "- ***3.695.csv***: （**Ashish Patel(阿希什)**による提出物。オリジナルのモデルではこのスコアに到達できなかったため、このアイデアを使って提出物を改善し、より良いLBスコアを得ることを試みます。）\n",
    "\n",
    "このパイプラインの流れは以下の通りです：\n",
    "1. 外れ値のないトレーニングセットを使ってモデルをトレーニングします。（得られるモデルを**`Model_1`**とします）\n",
    "2. 外れ値を分類するモデルをトレーニングします。（得られるモデルを**`Model_2`**とします）\n",
    "3. **`Model_2`**を使用してテストセット内のcard_idが外れ値かどうかを予測します。（得られるのは**`Outlier_Likelyhood`**です）\n",
    "4. **`Outlier_Likelyhood`**のスコアが上位10%（または他の割合）のcard_idを分割します。（得られるのは**`Outlier_ID`**です）\n",
    "5. 最良の提出物を使って**`Outlier_ID`**をテストセット内で予測し、残りのテストセットは**`Model_1`**を使って予測します。\n",
    "\n",
    "このパイプラインの基本的なアイデアは以下の通りです：\n",
    "1. 外れ値のないモデルをトレーニングすることで、非外れ値に対してモデルの精度を向上させる。\n",
    "2. 多くのエラーは外れ値によって引き起こされるため、外れ値を予測するためのモデルが必要です。それらを見つける方法は？分類器を構築することです！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928d710c",
   "metadata": {
    "_uuid": "7dd3ea3236069cf9706e377d6594c39b5e5a5507"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9fe05",
   "metadata": {
    "_uuid": "fcf141a7658f4089b1de2822ba41da9646c73835"
   },
   "source": [
    "# Part 1 Training Model Without Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dead074d",
   "metadata": {
    "_uuid": "aef67435b765a8c55e8a7653b47ad8d9071ea11b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/predicting-outliers-to-improve-your-score/train_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kento.nishino.ek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kento.nishino.ek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\kento.nishino.ek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kento.nishino.ek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\kento.nishino.ek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/predicting-outliers-to-improve-your-score/train_clean.csv'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv('../input/predicting-outliers-to-improve-your-score/train_clean.csv')\n",
    "df_test = pd.read_csv('../input/predicting-outliers-to-improve-your-score/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62e567",
   "metadata": {
    "_uuid": "18d93d315eee398fb1cff4ad8d115c21d359cd49"
   },
   "source": [
    "## filtering out outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d0382",
   "metadata": {
    "_uuid": "3eb5ac784a25271b3433f6371d7b46cdabb420b5"
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['outliers'] == 0]\n",
    "target = df_train['target']\n",
    "del df_train['target']\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128f9ff",
   "metadata": {
    "_uuid": "8256bfde460ac4adc45852228a12194b2be6b497"
   },
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07814631",
   "metadata": {
    "_uuid": "a0ecb4a6605d477b290275f404a508bfacd614e0"
   },
   "outputs": [],
   "source": [
    "param = {'objective':'regression',\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 25,\n",
    "         'max_depth': 7,\n",
    "         'learning_rate': 0.01,\n",
    "         'lambda_l1':0.13,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\":0.85,\n",
    "         'bagging_freq':8,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"metric\": 'rmse',\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b9b1b",
   "metadata": {
    "_uuid": "204231995912b388ad8d6bed1c602c6fa29ebb4a"
   },
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086e00a",
   "metadata": {
    "_uuid": "1f153534282a64ea904b599143b023f56bf01e05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval= 100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9440c03",
   "metadata": {
    "_uuid": "4842069eb5b3fa8617b624c1d2fd00940c75137e"
   },
   "outputs": [],
   "source": [
    "model_without_outliers = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "model_without_outliers[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b56624",
   "metadata": {
    "_uuid": "60b9a679754a23f8a07a4e06bf2003abdfbe57db"
   },
   "source": [
    "# Part 2 Training Model For Outliers Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03b907",
   "metadata": {
    "_uuid": "3f28c4be6b16f4e9d9e66d309a1c8f00175653f1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv('../input/predicting-outliers-to-improve-your-score/train_clean.csv')\n",
    "df_test = pd.read_csv('../input/predicting-outliers-to-improve-your-score/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04035e40",
   "metadata": {
    "_uuid": "c2410c958c49b761f042ecdf5619af54730865d3"
   },
   "source": [
    "## using outliers column as labels instead of target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d9b40",
   "metadata": {
    "_uuid": "19cf3932dbbbc42a8e7e0c50ac7ae4c74fd15f62"
   },
   "outputs": [],
   "source": [
    "target = df_train['outliers']\n",
    "del df_train['outliers']\n",
    "del df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9d8c8",
   "metadata": {
    "_uuid": "a60cc387b88592ae2ae6ad78f33d6adcce22780d"
   },
   "outputs": [],
   "source": [
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47169fdb",
   "metadata": {
    "_uuid": "8867a7ba6c07d9a6c0ee04277960ff4d9c1559a8"
   },
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40439c66",
   "metadata": {
    "_uuid": "b067562422807b5f08688c9c91e22c86998b07c8"
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535c7be",
   "metadata": {
    "_uuid": "7664c74d5ed84d82d0a045b5f2862cf813a52fd8"
   },
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1ec47",
   "metadata": {
    "_uuid": "292376354fc58ca097cc04128d31f3117c648653",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea47da",
   "metadata": {
    "_uuid": "41f9c7d0a52f8d5669704619fdf76ad1451afaa2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 'target' is the probability of whether an observation is an outlier\n",
    "df_outlier_prob = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "df_outlier_prob[\"target\"] = predictions\n",
    "df_outlier_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5bb3ac",
   "metadata": {
    "_uuid": "a6cdbee1c92967a2ecb3924ab58af8d86675df31"
   },
   "source": [
    "\n",
    "# パート3：提出物の組み合わせ\n",
    "ここまで順調です！\n",
    "今、3つのデータセットがあります：\n",
    "\n",
    "1. 最良の提出物\n",
    "2. 外れ値のないモデルを使用した予測\n",
    "3. テストセット内の外れ値の確率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f791453",
   "metadata": {
    "_uuid": "d56e431808a9a70a102491ac7d77e4404e312a4b"
   },
   "outputs": [],
   "source": [
    "# テストセットにトレーニングセットと同じ割合の外れ値がある場合、 \n",
    "# テストセットの外れ値の数は約次の通りです：（トレーニングセットの外れ値は1.06％）\n",
    "123623*0.0106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd7b18",
   "metadata": {
    "_uuid": "40e683026c0e476bae7d15a759b97fa027af977d"
   },
   "outputs": [],
   "source": [
    "# 予測可能な外れ値を見逃す場合に備えて、外れ値の可能性が最も高い上位25,000を選択します。\n",
    "outlier_id = pd.DataFrame(df_outlier_prob.sort_values(by='target',ascending = False).head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e529bb",
   "metadata": {
    "_uuid": "e4c9575fad64e1cf9bd38e48fcf5e988b850189f"
   },
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../input/predicting-outliers-to-improve-your-score/3.695.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e575c",
   "metadata": {
    "_uuid": "7c6f4c87221dd9fa0bf2f87a60e46abbe39f7164",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_likely_liers = best_submission.merge(outlier_id,how='right')\n",
    "most_likely_liers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e8bc4",
   "metadata": {
    "_uuid": "0f1518b58748e9dd2ef3c1d92f161d03f923bac5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for card_id in most_likely_liers['card_id']:\n",
    "    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target']\\\n",
    "    = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8a9b9",
   "metadata": {
    "_uuid": "21e2c892dc716481293cb0b34f6b67be3a912aa9"
   },
   "outputs": [],
   "source": [
    "model_without_outliers.to_csv(\"combining_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
