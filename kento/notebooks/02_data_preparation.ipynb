{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込みと前処理を行うためのnotebookです。  \n",
    "モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df):\n",
    "    \"\"\"\n",
    "    指定された列を二値化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        二値化対象のデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        二値化されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    指定されたファイルからデータを読み込み、前処理を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        読み込むデータファイルのパス。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        前処理されたデータフレーム。\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('../data/raw/train.csv')\n",
    "test = read_data('../data/raw/test.csv')\n",
    "\n",
    "new_transactions = pd.read_csv('../data/raw/new_merchant_transactions.csv',\n",
    "                               parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merge = pd.merge(train, history, on='card_id', how='left')\n",
    "\n",
    "new_transactions = pd.read_csv('../data/raw/new_merchant_transactions.csv',\n",
    "                               parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_month_diff(transactions):\n",
    "    \"\"\"\n",
    "    purchase_dateとmonth_lagを基にmonth_diffを計算する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        month_diff列が追加されたデータフレーム。\n",
    "    \"\"\"\n",
    "    current_date = pd.Timestamp(datetime.datetime.today())\n",
    "    transactions['month_diff'] = ((current_date - transactions['purchase_date']).dt.days) // 30\n",
    "    transactions['month_diff'] += transactions['month_lag']\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df, columns):\n",
    "    \"\"\"\n",
    "    指定されたカテゴリカル列をワンホットエンコーディングする。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        エンコード対象のデータフレーム。\n",
    "    columns : list of str\n",
    "        エンコードするカテゴリカル列のリスト。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ワンホットエンコードされたデータフレーム。\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_transactions(history):\n",
    "    \"\"\"\n",
    "    取引データを集計する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_A': ['mean'],\n",
    "        'category_3_B': ['mean'],\n",
    "        'category_3_C': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_day': ['mean', 'max', 'min', 'std'], # 購入日\n",
    "        'purchase_dayofweek': ['mean', 'max', 'min', 'std'], # 購入曜日\n",
    "        'is_weekend': ['mean', 'max', 'min', 'std'], # 週末購入フラグ\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['mean', 'max', 'min', 'std'],\n",
    "        'month_diff': ['mean']\n",
    "    }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "\n",
    "def aggregate_per_month(history):\n",
    "    \"\"\"\n",
    "    月ごとの取引データを集計する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        月ごとに集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "        'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "        'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "    }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "\n",
    "\n",
    "def successive_aggregates(df, field1, field2):\n",
    "    \"\"\"\n",
    "    指定されたフィールドを基に連続集計を行う。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    field1 : str\n",
    "        集計の基準となるフィールド。\n",
    "    field2 : str\n",
    "        集計されるフィールド。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        連続集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    t = df.groupby(['card_id', field1])[field2].mean()\n",
    "    u = pd.DataFrame(t).reset_index().groupby('card_id')[field2].agg(['mean', 'min', 'max', 'std'])\n",
    "    u.columns = [field1 + '_' + field2 + '_' + col for col in u.columns.values]\n",
    "    u.reset_index(inplace=True)\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df, date_col):\n",
    "    # df = df['card_id']\n",
    "    df['purchase_month'] = df[date_col].dt.month\n",
    "    df['purchase_day'] = df[date_col].dt.day\n",
    "    df['purchase_dayofweek'] = df[date_col].dt.dayofweek\n",
    "    df['is_weekend'] = (df[date_col].dt.weekday >= 5).astype(int)\n",
    "    return df\n",
    "\n",
    "# データ準備\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "\n",
    "# 時間関連の特徴量作成\n",
    "historical_transactions = add_time_features(historical_transactions, 'purchase_date')\n",
    "new_transactions = add_time_features(new_transactions, 'purchase_date')\n",
    "authorized_transactions = add_time_features(authorized_transactions, 'purchase_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 144.02 Mb (55.9% reduction)\n",
      "Mem. usage decreased to 93.60 Mb (60.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "# 月の差を計算\n",
    "historical_transactions = calculate_month_diff(historical_transactions)\n",
    "new_transactions = calculate_month_diff(new_transactions)\n",
    "\n",
    "# カテゴリカル列をワンホットエンコーディング\n",
    "historical_transactions = encode_categorical_columns(historical_transactions, ['category_2', 'category_3'])\n",
    "new_transactions = encode_categorical_columns(new_transactions, ['category_2', 'category_3'])\n",
    "\n",
    "# メモリ使用量の削減\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "# authorized_flagの平均を計算\n",
    "agg_fun = {'authorized_flag': ['mean']}\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "\n",
    "# purchase_month列を追加\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "\n",
    "# データの集計\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "\n",
    "# 月ごとのデータの集計\n",
    "final_group = aggregate_per_month(authorized_transactions)\n",
    "\n",
    "# 連続集計\n",
    "additional_fields = successive_aggregates(new_transactions, 'category_1', 'purchase_amount')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'installments', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'city_id', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'category_1', 'installments'), on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, additional_fields, on='card_id', how='left')\n",
    "test = pd.merge(test, additional_fields, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>installments_purchase_amount_max</th>\n",
       "      <th>installments_purchase_amount_std</th>\n",
       "      <th>city_id_purchase_amount_mean</th>\n",
       "      <th>city_id_purchase_amount_min</th>\n",
       "      <th>city_id_purchase_amount_max</th>\n",
       "      <th>city_id_purchase_amount_std</th>\n",
       "      <th>category_1_installments_mean</th>\n",
       "      <th>category_1_installments_min</th>\n",
       "      <th>category_1_installments_max</th>\n",
       "      <th>category_1_installments_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>245</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.575822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.459000</td>\n",
       "      <td>-0.606574</td>\n",
       "      <td>-0.296143</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>396</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.725911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.725911</td>\n",
       "      <td>-0.725911</td>\n",
       "      <td>-0.725911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>549</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.700195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.700195</td>\n",
       "      <td>-0.700195</td>\n",
       "      <td>-0.700195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566895</td>\n",
       "      <td>0.080908</td>\n",
       "      <td>-0.664185</td>\n",
       "      <td>-0.665283</td>\n",
       "      <td>-0.663086</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175903</td>\n",
       "      <td>0.199291</td>\n",
       "      <td>-0.534717</td>\n",
       "      <td>-0.671143</td>\n",
       "      <td>-0.326765</td>\n",
       "      <td>0.150666</td>\n",
       "      <td>1.220588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.395148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  elapsed_time  hist_transactions_count  hist_category_1_sum  \\\n",
       "0 -0.820283           245                     13.0                  0.0   \n",
       "1  0.392913           396                     11.0                  2.0   \n",
       "2  0.688056           549                      2.0                  0.0   \n",
       "3  0.142495           153                      NaN                  NaN   \n",
       "4 -0.159749            92                      5.0                  3.0   \n",
       "\n",
       "   hist_category_1_mean  ...  installments_purchase_amount_max  \\\n",
       "0              0.000000  ...                         -0.575822   \n",
       "1              0.181818  ...                         -0.725911   \n",
       "2              0.000000  ...                         -0.700195   \n",
       "3                   NaN  ...                         -0.566895   \n",
       "4              0.600000  ...                         -0.175903   \n",
       "\n",
       "   installments_purchase_amount_std  city_id_purchase_amount_mean  \\\n",
       "0                               NaN                     -0.459000   \n",
       "1                               NaN                     -0.725911   \n",
       "2                               NaN                     -0.700195   \n",
       "3                          0.080908                     -0.664185   \n",
       "4                          0.199291                     -0.534717   \n",
       "\n",
       "   city_id_purchase_amount_min  city_id_purchase_amount_max  \\\n",
       "0                    -0.606574                    -0.296143   \n",
       "1                    -0.725911                    -0.725911   \n",
       "2                    -0.700195                    -0.700195   \n",
       "3                    -0.665283                    -0.663086   \n",
       "4                    -0.671143                    -0.326765   \n",
       "\n",
       "   city_id_purchase_amount_std  category_1_installments_mean  \\\n",
       "0                     0.155779                      0.000000   \n",
       "1                          NaN                      1.000000   \n",
       "2                          NaN                      0.000000   \n",
       "3                     0.001554                      0.833333   \n",
       "4                     0.150666                      1.220588   \n",
       "\n",
       "   category_1_installments_min  category_1_installments_max  \\\n",
       "0                     0.000000                          0.0   \n",
       "1                     1.000000                          1.0   \n",
       "2                     0.000000                          0.0   \n",
       "3                     0.666667                          1.0   \n",
       "4                     0.941176                          1.5   \n",
       "\n",
       "   category_1_installments_std  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                     0.235702  \n",
       "4                     0.395148  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 199)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理終了後のデータの保存\n",
    "- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n",
    "- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240626_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240626_test.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加の特徴量[1]\n",
    "# authorized_flag=0だけでmonth_diffの平均を取る\n",
    "# authorized_flag=0のフィルターを作成\n",
    "filter_authorized = historical_transactions[historical_transactions['authorized_flag'] == \"N\"].copy()\n",
    "# 現在の日時を取得\n",
    "current_date = pd.Timestamp(datetime.datetime.today())\n",
    "filter_authorized['purchase_date'] = pd.to_datetime(filter_authorized['purchase_date'])\n",
    "\n",
    "# 月差分（month_diff）を計算し、新しい列として追加\n",
    "filter_authorized['fil0_month_diff'] = (((current_date - filter_authorized['purchase_date']).dt.days) // 30).astype('int32')\n",
    "\n",
    "# 月の異常な取引を算出\n",
    "filter_authorized['fil0_month_diff'] += filter_authorized['month_lag']\n",
    "# card_idごとにmonth_diffの平均値をとる\n",
    "month_diff_mean = filter_authorized.groupby('card_id')['fil0_month_diff'].agg(['mean', 'min', 'max']).astype('float32').reset_index()\n",
    "month_diff = month_diff_mean.rename(columns={\n",
    "    'mean': 'fill0_month_diff_mean',\n",
    "    'min': 'fill0_month_diff_min',\n",
    "    'max': 'fill0_month_dfll_max'\n",
    "}).reset_index()\n",
    "# month_diff.head()\n",
    "\n",
    "# 追加の特徴量[2]\n",
    "# 最後に購入した日の購入額\n",
    "# 最後に購入した日\n",
    "last_purchase_date = historical_transactions.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "\n",
    "# 最終購入日の金額を取得する\n",
    "merge_last_purchase = pd.merge(last_purchase_date, historical_transactions[['card_id', 'purchase_date', 'purchase_amount']], on=['card_id', 'purchase_date'], how='inner')\n",
    "\n",
    "# card_id, purchase_dateごとのpurchase_amountの最大値、最小値、中央値、平均値を算出する。\n",
    "merge_last_purchase_agg = merge_last_purchase.groupby(['card_id', 'purchase_date'])['purchase_amount'].agg(['mean', 'min', 'max']).astype('float32').reset_index()\n",
    "\n",
    "# カラム名を変更する\n",
    "re_last_purchase = merge_last_purchase_agg.rename(columns={\n",
    "    'mean': 'last_purchase_amount_mean',\n",
    "    'min': 'last_purchase_amount_min',\n",
    "    'max': 'last_purchase_amount_max'\n",
    "}).reset_index()\n",
    "df_last_purchase = re_last_purchase[['card_id', 'last_purchase_amount_mean', 'last_purchase_amount_min', 'last_purchase_amount_max']]\n",
    "\n",
    "# 追加の特徴量[3]\n",
    "# 一番取引額が多い\n",
    "max_amount = historical_transactions.groupby('card_id').agg({'purchase_amount': 'max'}).astype('float32').reset_index()\n",
    "max_amount.rename(columns={'purchase_amount': 'max_purchase_amount'}, inplace=True)\n",
    "\n",
    "# 追加の特徴量[4]\n",
    "# 最高購入金額 - 最小購入金額\n",
    "amount_diff = historical_transactions.groupby('card_id')['purchase_amount'].agg({'max', 'min'}).reset_index()\n",
    "amount_diff['max_min_amount_dff'] = amount_diff['max'] - amount_diff['min']\n",
    "diff_amount = amount_diff[['card_id', 'max_min_amount_dff']]\n",
    "\n",
    "# 追加の特徴量[5]\n",
    "# purchase_date を日付型に変換\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "\n",
    "# 今日の日付を取得\n",
    "current_date = pd.Timestamp(datetime.datetime.today())\n",
    "\n",
    "# first_last_dates を作成\n",
    "first_last_dates = historical_transactions.groupby('card_id').agg({\n",
    "    'purchase_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# 取引期間を計算\n",
    "first_last_dates.columns = ['card_id', 'first_purchase_date', 'last_purchase_date']\n",
    "first_last_dates['transaction_days'] = (first_last_dates['last_purchase_date'] - first_last_dates['first_purchase_date']).dt.days\n",
    "\n",
    "# month_lag はそのまま使う\n",
    "df_his = historical_transactions[['card_id', 'purchase_date', 'month_lag']]\n",
    "\n",
    "# 不要な列を削除\n",
    "del historical_transactions\n",
    "\n",
    "# 月差分（month_diff）を計算し、新しい列として追加\n",
    "df_his['month_diff'] = (((current_date - df_his['purchase_date']).dt.days) // 30).astype('int16')\n",
    "df_his['month_diff'] += df_his['month_lag']\n",
    "\n",
    "# 不要な列を削除\n",
    "df_his.drop(columns=['purchase_date', 'month_lag'], inplace=True)\n",
    "\n",
    "# card_id ごとに month_diff の平均値を計算\n",
    "df_his_mean = df_his.groupby('card_id').agg({'month_diff': 'mean'}).astype('float32').reset_index()\n",
    "\n",
    "# killer_feature を作成\n",
    "killer_feature = pd.merge(df_his_mean, first_last_dates, on='card_id', how='inner')\n",
    "killer_feature['kil_feature'] = killer_feature['month_diff'] / killer_feature['transaction_days']\n",
    "killer_feature['kil_feature'] = killer_feature['kil_feature'].astype('float32')\n",
    "\n",
    "# 不要な列を削除\n",
    "killer_feature.drop(columns=['first_purchase_date', 'month_diff', 'last_purchase_date', 'transaction_days'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = pd.merge(train, month_diff, on='card_id', how='left')\n",
    "test = pd.merge(test, month_diff, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, df_last_purchase, on='card_id', how='left')\n",
    "test = pd.merge(test, df_last_purchase, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, max_amount, on='card_id', how='left')\n",
    "test = pd.merge(test, max_amount, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, diff_amount, on='card_id', how='left')\n",
    "test = pd.merge(test, diff_amount, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, killer_feature, on='card_id', how='left')\n",
    "test = pd.merge(test, killer_feature, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 210)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 209)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240626_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240626_test.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
